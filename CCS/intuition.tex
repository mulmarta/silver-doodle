\section{The \saik Protocol}\label{sec:intuition}
In this section, we build intuition for the \saik construction. A detailed description of \saik together with pseudocode can be found in \cref{sec:saik-details}.

\saik inherits most of its mechanisms from \protITK, the CGKA of \mls. We recall the \protITK construction in \cref{sec:intuition1}. Readers familiar with it can jump directly to \cref{sec:intuition2} which explains how \saik improves in \protITK.

\subsection{The \protITK Protocol}\label{sec:intuition1}
\paragraph{The Authenticated Key Service (AKS).}
\protITK relies on an Authenticated Key Service (AKS) which authentically distributes so-called one-time key packages (also called key bundles or pre-keys) used to add new members to the group without interacting with them. For simplicity, we use an idealized AKS which guarantees that a fresh, authentic and honestly generated key package of any user is always available. We elaborate on all the simplifications in \cref{sec:simplifications}.

\paragraph{Ratchet trees.}
The operation of \protITK relies on a data structure called ratchet trees. A ratchet tree $\tree$ is a tree where leaves are assigned to group members. Leaves of $\tree$ store information about their members' identities and signature key pairs. Moreover, most non-root nodes in $\tree$, store encryption key pairs. Nodes without a key pair are called \emph{blank}.

\protITK maintains the following \emph{tree invariant}:
\begin{enumerate}[itemsep=0pt]
  \item Each member knows all public keys in $\tree$.
  \item Each member knows the secret keys of the nodes on the path from their leaf to the root, and only those.
\end{enumerate}
The invariant allows to efficiently encrypt messages to subgroups: If a node $v$ is not blank, then a message $m$ can be encrypted to all members in the subtree of a node $v$ by encrypting it under $v$'s public key. If $v$ is blank, then the same can be achieved by encrypting $m$ under each key in $v$'s \emph{resolution}, i.e., the minimal set of non-blank nodes covering all leaves in $v$'s subtree.

%\saik uses generalized $q$-ary ratchet trees, generalizing binary trees used by \protITK (and all its variants). While in most applications $q=2$ is optimal, choosing $q>2$ is more efficient if \saik is instantiated with (an mmPKE built from) a post-quantum secure mKEM \cite{AC:KKPP20}.

\paragraph{Ratchet tree evolution.}
Each group modification corresponds to a modification of the ratchet tree $\tree$. Most importantly, an update performed by a member $\id$ corresponds to refreshing all key pairs with secret keys known to $\id$, i.e., those in the nodes on the path from $\id$'s leaf to the root. $\id$ generates the new key pairs and, to maintain the tree invariant, communicates the secret keys to some group members. This is done efficiently as follows.
\begin{enumerate}[itemsep=0pt]
  \item Let $v_1, \dots, v_n$ denote the nodes on the path from $\id$'s leaf $v_1$ to the root $v_n$.
  \item $\id$ generates a sequence of \emph{path secrets} $s_2, \dots, s_n$ (bitstrings of length equal to the security parameter) by picking $s_2$ at random and computing $s_{i+1} = \hash(s_i,\literal{path})$.
  \item $\id$ generates a fresh key pair for $v_1$. For each $i\in[2,n-1]$, the new key pair of $v_i$ is computed by
    running the key generation with randomness $\hash(s_i,\literal{rand})$. The last secret $s_n$ will be used in the key schedule, described soon.
  \item $\id$ encrypts each $s_{i+1}$ to the sibling of $v_i$. This allows members in the subtree of $v_i$ (and only those) to derive all secrets $s_{i+1}, \dots, s_n$.
\end{enumerate}
Each other group modification is immediately followed by an implicit update.

Removing a member $\id_t$ corresponds to removing all key pairs known to it, i.e., blanking all nodes on the path from its leaf to the root.

Adding a member $\id_t$ corresponds to inserting a new leaf into $\tree$. The leaf's public signature and encryption keys are fetched from the AKS. Further, the new leaf becomes an \emph{unmerged leaf} of all nodes on the path from it to the root. A leaf $l$ being unmerged at a node $v$ indicates that the $l$'s owner does not know the secret key in $v$, so messages should be encrypted directly to the leaf. When $v$'s key is refreshed during an update, its set of unmerged leaves is cleared.

\paragraph{Key schedule.}
Apart from the ratchet tree, all group members store a number of shared symmetric keys, unique to the current epoch. These are: the \emph{application secret} --- the group key exported to the E2E application, the \emph{membership key} used to authenticate sent messages and te \emph{init key} --- mixed in the next epoch's application secret for FS.

The secrets are derived when an epoch is created, i.e. after the implicit update following each modification. The update generates the last path secret $s_n$, which we now call the commit secret. Then, the following secrets are derived. First, the commit and the old epoch's init secrets are hashed together to obtain the \emph{joiner secret}. Then, the \emph{epoch secret} is obtained by hashing the joiner with the new epoch's \emph{context}, which we explain next. (The context is not mixed directly with init and commit secrets, because the joiner secret is needed by new members; see below.) Finally, the new epoch's application, membership and init secrets are obtained by hashing the epoch secret with different labels.

The context of an epoch includes all relevant information about it, such as (the hash of) the ratchet tree (which includes the member set). Intuitively, the purpose of mixing it into the key schedule is ensuring that if members are in different epochs with different contexts, then they derive independent epoch secrets.

\paragraph{Joining.}
When an $\id_t$ joins a group, the party inviting them encrypts to them two secrets under a key fetched from the AKS. First, this is $\id_t$'s path secret from the implicit update following the add. Second, this is the new joiner secret, from which $\id_t$ derives other epoch secrets.
Importantly, the new member hashes the joiner with the context, which means that it agrees on the epoch's state with all current members transitioning to it.

\subsection{The \saik Protocol}\label{sec:intuition2}
\paragraph{mmPKE.}
In \protITK, a member performing an update generates a sequence of path secrets $s_1, \dots, s_n$ and encrypts each $s_i$ to each public key from a set of recipient public keys $S_i$ using regular encryption.
In contrast, \saik redraws its internal abstraction boundaries viewing the sequence of encryptions as a single call to mmPKE.
This allows \saik to use the ElGamal-based mmPKE construction of
~\cite{ASIACCS:PinPoeSch14}. Compared to \protITK, this cuts both the
computational complexity of encrypting $\vec m$ and the resulting ciphertext
size in half (asymptotically as $n$ grows).

The mmPKE of~\cite{ASIACCS:PinPoeSch14} is straightforward. Let $\dem$ be a
data encapsulation scheme and $\kdf$ be a Key Derivation
Function.\footnote{In \saik we can instantiate $\dem$ with an off-the-shelf
AEAD such as AES-GCM and $\kdf$ with HKDF.} Recall that a (generalized)
ElGamal encryption of $m$ to public key $g^x$ requires sampling coins $r$ to
obtain ciphertext $(g^r, \dem(k_m, m))$ where $k_m = \kdf(g^{rx}, g^x)$. The
mmPKE variant reuses coins $r$ from the first ElGamal ciphertext to encrypt
all subsequent plaintexts. Thus, the final ciphertext has the form $(g^r,
\dem(k_1, m_1), \dem(k_2, m_2),\ldots)$ where $k_i = \kdf(g^{rx_i},
g^{x_i})$.

\paragraph{Optimizing for Short Messages.}
Normally, when messages $m$ can have arbitrary size, a sensible mmPKE would use a
KEM{\textbackslash}DEM style construction to avoid having to re-encrypt $m$
multiple times. In other words, for each $m$ in the encrypted vector, we choose a fresh key $k'_m$
for an AEAD and encrypt $m$ with $k'_m$. Then use the mmPKE of
\cite{ASIACCS:PinPoeSch14} to encrypt $k'_m$ to each public key receiving $m$.
However, since the secrets encrypted in \saik have the same length as AEAD
keys, in our case it is more efficient to encrypt the secrets directly.
We refer to Figure~\ref{fig:mmpke_constr} in
Section~\ref{sec:mmpke} for the details of the construction.
%
We remark that the security notion of \cite{ASIACCS:PinPoeSch14} does not
permit such an optimization.\footnote{The
  reason is that they require the mmPKE to hide if two recipients get the same message. In contrast, it is permitted by our notion parameterized by larger leakage function. The security proof of \saik works with the larger leakage too.}

\paragraph{Authentication.}
The goal of authentication is to make sure that a member accepts a message from $\id$ only if $\id$ knows 1) the signing key for the verification key stored in $\id$'s leaf in the current ratchet tree and 2) the current key schedule.
In \protITK, where every member gets the same message, this is achieved by simply signing it and MACing with the current membership key.
In \saik, to optimize bandwidth, the mailboxing service forwards to each receiver
only the data it needs. For instance, it does not forward ciphretexts for other members. Therefore, we have to achieve authentication differently.

One trivial solution would be for the sender to upload multiple signatures, one for each receiver. However, this clearly does not scale. Can we do something better?
A crucial observation is that the goal of saCGKA is to authenticate epochs and \emph{not message bitstrings}. In other words, we want to guarantee that if Alice thinks that a message $c$ transitions her to an epoch $E$ created by Bob, then Bob indeed created $E$. It is not an attack if the adversary can make Alice accept a message that is not extracted according to the honest procedure, as long as it transitions her to $E$. For instance, it may be fine to re-order different fields of $c$ as long as Alice can interpret them.

Therefore, instead of signing the whole message, in \saik we can sign and MAC only a single short tag that identifies the new epoch and is known to all members. In particular, this value is derived in the key schedule for the new epoch, alongside the other secrets, by hashing the epoch secret with an appropriate label.

We note that this optimization is enabled by our new, more accurate, saCGKA security definition.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
